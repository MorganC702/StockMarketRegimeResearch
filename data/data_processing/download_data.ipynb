{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42145380",
   "metadata": {},
   "source": [
    "# Downloading The Datasets\n",
    "\n",
    "Prior to this step we have manually downloaded a number of economic datasets from https://fred.stlouisfed.org/ including informationon commodities, consumer sentiment, external trade, growth and activity, housing and construction, inflation, interest, labor, market sentiment, and monetary conditions. We will be combining these economic indicators with daily features representing the SPY index, and foreign currency data. \n",
    "\n",
    "In this step we will be downloading the SPY index dataset for a 5 year historical period from the Polygon.io API, and historical data for the 8 major foreign currency pairs from the Yfinance API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab84470",
   "metadata": {},
   "source": [
    "#### Step 1: Download SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c53bd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET SPY\n",
      "  -> 1,255 rows → ../../data/downloaded/polygon/SPY.csv\n"
     ]
    }
   ],
   "source": [
    "import os, requests\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = os.getenv(\"POLYGON_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise SystemExit(\"Set POLYGON_API_KEY env var.\")\n",
    "\n",
    "OUT_DIR = Path(\"../../data/downloaded/polygon\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "start = \"2000-01-01\"\n",
    "end   = date.today().isoformat()\n",
    "\n",
    "tickers = [\n",
    "    \"SPY\",   # S&P 500 ETF (equity)\n",
    "]\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for tkr in tickers:\n",
    "    url = (\n",
    "        f\"https://api.polygon.io/v2/aggs/ticker/{tkr}/range/1/day/\"\n",
    "        f\"{start}/{end}?adjusted=true&sort=asc&limit=50000&apiKey={API_KEY}\"\n",
    "    )\n",
    "    print(\"GET\", tkr)\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        print(\"  -> HTTP\", r.status_code, r.text[:200])\n",
    "        continue\n",
    "\n",
    "    js = r.json()\n",
    "    res = js.get(\"results\", [])\n",
    "    if not res:\n",
    "        print(\"  -> no results\")\n",
    "        continue\n",
    "\n",
    "    df = pd.DataFrame(res)\n",
    "    if \"t\" not in df.columns:\n",
    "        print(\"  -> no 't' column in results; skipping\")\n",
    "        continue\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"t\"], unit=\"ms\", utc=True).dt.tz_localize(None).dt.normalize()\n",
    "    df[\"ticker\"] = tkr\n",
    "\n",
    "    keep = {\n",
    "        \"date\": \"date\",\n",
    "        \"o\": \"open\",\n",
    "        \"h\": \"high\",\n",
    "        \"l\": \"low\",\n",
    "        \"c\": \"close\",\n",
    "        \"v\": \"volume\",\n",
    "        \"vw\": \"vwap\",\n",
    "        \"n\": \"transactions\",\n",
    "        \"ticker\": \"ticker\",\n",
    "    }\n",
    "    \n",
    "    df = df[[k for k in keep if k in df.columns]].rename(columns=keep).sort_values(\"date\")\n",
    "\n",
    "    safe_name = tkr.replace(\":\", \"_\")\n",
    "    out_file = OUT_DIR / f\"{safe_name}.csv\"\n",
    "    df.to_csv(out_file, index=False)\n",
    "    print(f\"  -> {len(df):,} rows → {out_file}\")\n",
    "\n",
    "    all_rows.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8e564",
   "metadata": {},
   "source": [
    "#### Step 2: Download Foreign Currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db473f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET EURUSD -> EURUSD=X\n",
      "  -> 5,650 rows → ../../data/downloaded/yfinance/EURUSD.csv\n",
      "GET USDJPY -> USDJPY=X\n",
      "  -> 6,670 rows → ../../data/downloaded/yfinance/USDJPY.csv\n",
      "GET GBPUSD -> GBPUSD=X\n",
      "  -> 5,662 rows → ../../data/downloaded/yfinance/GBPUSD.csv\n",
      "GET USDCHF -> USDCHF=X\n",
      "  -> 5,716 rows → ../../data/downloaded/yfinance/USDCHF.csv\n",
      "GET USDCAD -> USDCAD=X\n",
      "  -> 5,718 rows → ../../data/downloaded/yfinance/USDCAD.csv\n",
      "GET AUDUSD -> AUDUSD=X\n",
      "  -> 5,026 rows → ../../data/downloaded/yfinance/AUDUSD.csv\n",
      "GET NZDUSD -> NZDUSD=X\n",
      "  -> 5,651 rows → ../../data/downloaded/yfinance/NZDUSD.csv\n",
      "GET USDSEK -> USDSEK=X\n",
      "  -> 6,109 rows → ../../data/downloaded/yfinance/USDSEK.csv\n",
      "Merged → ../../data/downloaded/yfinance/fx_all_daily.csv  (46,202 rows)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "OUT_DIR = Path(\"../../data/downloaded/yfinance\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "start = \"2000-01-01\"\n",
    "end   = date.today().isoformat()\n",
    "\n",
    "# 8 majors (Yahoo Finance symbols use '=X')\n",
    "fx_map = {\n",
    "    \"EURUSD\": \"EURUSD=X\",\n",
    "    \"USDJPY\": \"USDJPY=X\",\n",
    "    \"GBPUSD\": \"GBPUSD=X\",\n",
    "    \"USDCHF\": \"USDCHF=X\",\n",
    "    \"USDCAD\": \"USDCAD=X\",\n",
    "    \"AUDUSD\": \"AUDUSD=X\",\n",
    "    \"NZDUSD\": \"NZDUSD=X\",\n",
    "    \"USDSEK\": \"USDSEK=X\",\n",
    "}\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for pair, yf_sym in fx_map.items():\n",
    "    print(\"GET\", pair, \"->\", yf_sym)\n",
    "    df = yf.download(yf_sym, start=start, end=end, interval=\"1d\",\n",
    "                     auto_adjust=False, progress=False, threads=True)\n",
    "    if df.empty:\n",
    "        print(\"  -> no data\")\n",
    "        continue\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        \"Open\": \"open\", \"High\": \"high\", \"Low\": \"low\", \"Close\": \"close\",\n",
    "        \"Adj Close\": \"adj_close\", \"Volume\": \"volume\"\n",
    "    })\n",
    "    df[\"date\"] = pd.to_datetime(df.index).tz_localize(None).normalize()\n",
    "    df[\"ticker\"] = f\"FX:{pair}\"\n",
    "    df = df[[\"date\", \"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\", \"ticker\"]]\n",
    "    df = df.reset_index(drop=True).sort_values(\"date\")\n",
    "\n",
    "    out_file = OUT_DIR / f\"{pair}.csv\"\n",
    "    df.to_csv(out_file, index=False)\n",
    "    print(f\"  -> {len(df):,} rows → {out_file}\")\n",
    "    all_rows.append(df)\n",
    "\n",
    "if all_rows:\n",
    "    merged = pd.concat(all_rows, ignore_index=True).sort_values([\"ticker\", \"date\"])\n",
    "    merged.to_csv(OUT_DIR / \"fx_all_daily.csv\", index=False)\n",
    "    print(f\"Merged → {OUT_DIR/'fx_all_daily.csv'}  ({len(merged):,} rows)\")\n",
    "else:\n",
    "    print(\"No FX data fetched.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
